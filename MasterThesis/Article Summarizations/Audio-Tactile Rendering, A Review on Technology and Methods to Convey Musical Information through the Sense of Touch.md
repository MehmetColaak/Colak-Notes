### Keywords
	human computer interaction, haptic music player, musical haptics, musical haptic wearables, sensory substitution systems, tactile rendering
### Introduction
The article systematically examines how vibrations can be used to communicate musical elements. The authors intend for this review to serve as a reference for researchers and artists working in areas such as haptics, assistive technologies, music, psychology, and human-computer interaction. The core of the article revolves around Haptic Music Players (HMPs), which are systems designed to translate music into touch sensations, and Audio-Tactile Rendering (ATR).

Shows categorized overview on different haptic music player devices and actuator could be used for tactile rendering like voice coil actuators, linear resonant actuators, piezoelectric actuators etc.
### Touch Translation in Different Auditory Categories
This part in the article is exploring tactile renderings(haptic translations) and perceptive effects on different type of auditory concepts such as rhythm, pitch, melody, timbre and loudness. 

**Rhythm:** Tactile rendering of rhythm explained in a basic way of filtering the music signal and using filtered signal as an exciter for an actuator. Rhythm is described as pattern of pulses in discrete time and rhythm as a musical feature may be perceived by multiple sensory channels such as visual, auditory, and touch. 

**Pitch:** Rendering pitch to vibrotactile stimuli is a complex task as touch has frequency perception limitations. A simple way to translate pitch and loudness to vibrotactile stimuli is using speakers or VCAs which directly convert pitch to frequency and loudness to intensity of vibrations. However, frequency response of these actuators overpass skin perception thresholds, so information embedded in high-frequency bands (i.e., over 1000 Hz) might be lost. One interesting highlight, consonance between pitches introduced as another important feature of music, although dissonance can also be used as a composing resource. It has been studied in and results show that users may process vibrotactile consonance in similar way as the auditory channel. So multimodal perception works in the same way when it comes to perceiving harmony.

**Melody:** Melody builds up as a suitable combination of pitch changes over time. Therefore, most of the limitations for pitch conversion also apply to melody.

**Timbre:** Timbre allows the listener to differentiate between tones played from one or another musical instrument. Timbre relies on the frequency content (i.e., spectral content) of audio signals and therefore tactile rendering represents a challenge. Although the reduced tactile perception band will affect the recognition of small spectral content variations, individuals are able to recognize timbre of rendered audio signals from different musical instruments (e.g., piano, cello, or trombone) with vibrotactile stimuli only. Moreover, the sense of touch is able to recognize waveform of signals, where the mechanoreceptors work as tactile filters that aid in the process. This recognition ability may be used as a tool to render texture of sound (i.e., timbre) as vibrotactile texture.

**Loudness:** In traditional music notation loudness is a key feature to consider. Subjectively, vibrotactile loudness is a variable corresponding to the distance that the skin is displaced by the stimuli. Tactile rendering of loudness may be straightforward as can be mapped directly to the intensity of the actuators
### Composing Music for Touch
Vibrotactile Music Composition (VMC) explores creating musical pieces specifically for the tactile sense. Key aspects include manipulating frequency, duration, intensity, waveform, spectral content, and the spatial location of vibrations.