### Keywords
	audio-tactile, haptics, multi-modal sensory, audio localization
### Where? Why?
I came across this article while I was reading another article about auditory-tactile interfaces and narratives. The article covers more specific subject about auditory-tactile interfaces which is audio-tactile interaction on spatial orientation(localization) in virtual scenes. It uses 2 different experiments to measure level of interaction by giving user auditory and tactile stimulations simultaneously. Study focuses on auditory-haptic "localization" in the spatial domain.

This study is important for my research subject because of I want to introduce an art project with my thesis which will use a lot of audio-tactile sensory stimuli for an immersive auditory environmental narration.
### Introduction
The writers of article are M. Ercan Altinsoy and Maik Stammâ€‹. They are both PhDs in human computer interaction from TU Dresden. Since sound produced by vibrations they are exploring the importance of audio-tactile stimulations for localization in virtual environments by transforming a multi-modal illusion(ventriloquism effect) from auditory and visual sensory fields to audio-tactile field.
### Main
Perceiving spatial orientation and localization in space is one of our multi-sensory(multi-modal) capabilities which is important for interaction with the environment around us.

During the evaluation of the multi-modal events, visual, tactile and auditory information interacts and possess influence between each other. Multi-modal illusions like ventriloquism effect is an auditory illusion in which sound is misperceived from a source when it has different position at visible source. The effect is most powerful for speech sounds, and it happens because of visual dominance over auditory information. It is exploited by stage ventriloquists who practise the art of speaking without moving their lips while manipulating the movements of a puppet. 

Although the multi-modal events determined by physical rules and usually has same position in physical world, it is possible to break this rules in virtual environments to have a control and optimization over object interaction in virtual environments.
### Experimentations
8 participants took part. For the audio-tactile content a hair shaving machine recorded with both microphone and an accelerometer. A loudspeaker array with nine loudspeakers was used to present the acoustic stimulus. Electrotactile stimulation was used to present the vibrations. The first experiment includes 2 phases, one audio stimulus directly ahaed of the subject and following another stimulus with a different position. In each run subject was asked to state whether second event lay to the right or to the left of the first.

In the second experiment same test was done with adding an electrotactile stimulation into test. Subjects were asked whether the position of the auditory event and the position of the tactile information coincide or not.
### Conclusion
Simultaneously presented electrotactile stimulation enlarges the localization blur and the tactile stimulation pulls the auditory source to the direction of its location. Audio-tactile interaction play an important role on the spatial orientation in virtual scenes. Therefore they should be taken into account in virtual reality applications.